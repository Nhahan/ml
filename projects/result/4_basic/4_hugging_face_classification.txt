2024-10-10 09:53:46,810 - INFO - Saving training log...

TrainOutput(global_step=12000, training_loss=0.14291523742675782, metrics={'train_runtime': 2534.7653, 'train_samples_per_second': 378.733, 'train_steps_per_second': 11.835, 'total_flos': 1.1424329685264384e+16, 'train_loss': 0.14291523742675782, 'epoch': 4.0})2024-10-10 09:53:46,810 - INFO - Evaluating on test data...
2024-10-10 09:53:58,681 - INFO - Test Accuracy: 0.9361
2024-10-10 09:53:58,681 - INFO - Predicting sample text...
2024-10-10 09:53:58,694 - INFO - Prediction: [{'label': 'WORLD', 'score': 0.9946638345718384}]
2024-10-10 21:05:54,110 - INFO - Loading dataset...
2024-10-10 21:06:02,654 - INFO - Preparing tokenizer...
2024-10-10 21:06:02,913 - INFO - Tokenizing dataset...
2024-10-10 21:06:02,980 - INFO - Loading model...
2024-10-10 21:06:03,276 - INFO - Setting up training arguments...
2024-10-10 21:06:04,501 - INFO - Initializing trainer...
2024-10-10 21:06:04,682 - INFO - Starting training...
2024-10-10 22:07:40,968 - INFO - Saving training log...

TrainOutput(global_step=12000, training_loss=0.14401940155029297, metrics={'train_runtime': 3695.5426, 'train_samples_per_second': 259.772, 'train_steps_per_second': 8.118, 'total_flos': 1.1451527868098304e+16, 'train_loss': 0.14401940155029297, 'epoch': 4.0})2024-10-10 22:07:40,968 - INFO - Evaluating on test data...
2024-10-10 22:07:58,141 - INFO - Test Accuracy: 0.9361
